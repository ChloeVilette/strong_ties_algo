# strong_ties_algo



To extract strong ties, it is common practice to select a user-determined number of social bonds (Silk 2006b, Schulke et al 2020). This approach means that all individuals are, in essence, arbitrarily allocated a certain number of strong bonds (i.e., partners with whom they interact most frequently) regardless of the actual frequency of interactions (i.e., the choices here are not based on any biologically or statistically principled criteria) (Silk et al 2010, Schulke et al 2010). Furthermore, restricting the analysis to a predetermined number of bonds eliminates the possibility of examining variability in the number of bonds formed by individuals. To address this issue, some studies have simply used higher than average composite sociality index (CSI) scores and lower than average CSI scores to identify strong and weakly bonded partners as a continuous measure (McFarland et al. 2015, Silk et al 2006a). Others used several thresholds to identify a strong tie from observational data alone and counted the number of strong ties with strength above (1) the 0.9 percentile, (2) the 3rd quartile, and (3) the mean value (see Schulke et al 2022) Yet, this approach also fails to consider the distribution of the data itself and more specifically, whether a clear distinction between weak and strong ties exists (i.e., whether there is a skewed distribution). In our analyses, we therefore developed an algorithm to model the distribution of edge weights on the assumption that, if strong ties (relatively large edge weights) were present, then the distribution of edge weights would be skewed. 

For each juvenile our model-based function proceeded as follows: 
1 - The weight distribution was extracted for a given time period, representing the total number of times the focal animal was recorded as interacting with each of its partners. 
2 – We ran two models (weights ~1), using the ‘brms’ package (Bürkner, 2017), specifying a skewed-normal and a normal distribution respectively. The priors for the mean weight (i.e., intercept) were adjusted in order to reflect the observed weak ties distribution (here normal (1,1)) and can be tailored to what is thought to be weak ties based on prior information. We also specified priors (normal (0,1)) on the sigma parameter, which defines the range of weak tie values around the mean weight. For the skewed-normal distribution, the intercept parameter was set with a normal prior with mean 1 and standard deviation 2, while the sigma parameter was set with a normal prior with mean 0 and standard deviation 10. Lastly, we also set a weakly informative prior with mean 0 and standard deviation 4 on the magnitude of skew in the data: i.e., alpha. To then check which distribution fitted the extracted weight distribution better, we compared the skewed-normal and normal distribution models using leave-one-out cross-validation (‘LOO’; Vehtari et al., 2016), which computed a formal difference score between the two models, with the ‘loo_compare’ function of ‘brms’.  The presence of small sample sizes (i.e., when an individual has only 1 or 2 partners), however, meant that the information present in the weight distribution alone was inadequate, leading to a very small and unreliable difference between a skewed and a normal distribution. To address this, we used a parameter “min_diff” to indicate how much evidence we were willing to accept in the difference score, computed using the leave-one-out cross-validation, between models with a skewed and a normal distribution in ties. It was set to five in order to make the selection of strong ties more conservative. This min_diff parameter constrained the algorithm to select only models for which there was strong evidence of a skewed distribution.
3.a - If a skewed distribution fit the data better, the largest weight within the distribution was classified as a strong tie. To search for the number of strong ties, we ran a model predicting weight using the classification of strong or weak tie. This model fitting approach compared, again using loo, possible classifications of strong vs. weak ties, starting the largest weight being the only classified as a strong tie, followed by the strongest and second strongest being strong ties, and so on. Once model comparison had found the best model, we used that classification of strong vs weak ties to define our strong and weak ties.
3.b - If the normal distribution was a better fit to the focal’ animal’s weight distribution, then no strong ties were recorded.
 
Overall, this algorithm follows the logic of a semi-supervised classification where some small bit of information (1-priors about what a weak tie looks like, and 2-those strong ties should result in a skewed distribution) is then used to help perform unsupervised classification. To assess our algorithm’s accuracy, we performed two tests. In the first, we simulated a normal distribution (i.e., no strong ties present) and recorded how many false positives (i.e., strong ties) our function detected. The second test consisted of adding one strong tie to a normal distribution. We then inferred how many times that strong tie was detected (i.e., true positives). Both tests were conducted on varying sample sizes (N = 2-50 interactions), with each sample size tested ten times. These simulations helped us tune our priors to get the best results on simulated data before applying it to our real data. Using these two tests, we compared our built function to commonly used methods for the extraction of strong ties, such as counts of strong ties (strength > 0.9 percentile) and strength of strong ties (top 3* ties of individual) (see Supplementary). As our function was more reliable in detecting strong ties, we proceeded to extract the strong ties present in our data using this model-based approach. While this algorithm performed better than measures previously used, it still needs work as some flaws remain. For instance, by setting our “min_diff” parameter to 5 it enables the algorithm to distinguish between strong and weak ties. Yet, the higher this parameter is set, the bigger the difference between a weak and strong tie must be when the sample size is small (e.g., with this weight distribution (1, 3,15) no strong tie was detected). Therefore, as the sample size between spatial and grooming behaviour differed, we set the “min_diff” parameter differently based on the studied behaviour. That is, when extracting strong ties in spatial associations, we set the parameter min_diff to 5 as the sample size per individual was higher than the grooming interactions where the parameter was lowered to 2. In fact, with a smaller sample size, the frequency of interactions (weights) will inevitably be lower and so the different between a weak and strong tie won’t be as strong.
